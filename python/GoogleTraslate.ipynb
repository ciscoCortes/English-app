{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95970415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la libreria request\n",
    "import requests\n",
    "\n",
    "def translate(text, source='en', target='es'):\n",
    "    params = {'sl': source, 'tl': target, 'q': text}\n",
    "    headers = {\"Charset\":\"UTF-8\",\"User-Agent\":\"AndroidTranslate/5.3.0.RC02.130475354-53000263 5.1 phone TRANSLATE_OPM5_TEST_1\"}\n",
    "    url = \"https://translate.google.com/translate_a/single?client=at&dt=t&dt=ld&dt=qca&dt=rm&dt=bd&dj=1&hl=es-ES&ie=UTF-8&oe=UTF-8&inputm=2&otf=2&iid=1dd3b944-fa62-4b55-b330-74909a99969e\"\n",
    "    response = requests.post(url, data=params, headers=headers)\n",
    "    if response.status_code == 200: \n",
    "        return response.json()\n",
    "    else:\n",
    "        print(\"Ocurrió un error\", text)\n",
    "        return \"Ocurrió un error\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c69ea0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Interfas para usuario\n",
    "import json\n",
    "\n",
    "count = 0\n",
    "while count < 1:\n",
    "    count += 1\n",
    "    text = input(\"Ingrese un texto para traducir: \")\n",
    "    respuesta = json.dumps(translate(text),ensure_ascii=False, indent = 2)\n",
    "    print(respuesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0bb52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"wordsList.json\", \"r\") as f:\n",
    "    wordsList = json.loads(f.read())\n",
    "    dicList = list(map(translate, wordsList))\n",
    "\n",
    "dictData = {}\n",
    "for x in dicList:\n",
    "    ID = x['sentences'][0]['orig']\n",
    "    dictData[ID] = x\n",
    "    \n",
    "with open(\"googleDict.json\", \"w\") as outfile:\n",
    "    json.dump(dictData, outfile, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "143a80fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def transEgs(meaning):\n",
    "    ejemplos = []\n",
    "    for eg in meaning[\"examples\"]:\n",
    "        ejemplos.append(translate(eg)[\"sentences\"][0][\"trans\"])\n",
    "    meaning[\"ejemplos\"] = ejemplos\n",
    "    return meaning\n",
    "\n",
    "\n",
    "with open(\"wikiData.json\", \"r\") as f:\n",
    "    wikiData = json.loads(f.read())\n",
    "    for word in wikiData:\n",
    "        wikiData[word][\"meanings\"] = list(map(transEgs, wikiData[word][\"meanings\"]))\n",
    "        \n",
    "with open(\"wikiData_es.json\", \"w\") as f:\n",
    "    json.dump(wikiData, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00caae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "with open(\"wikiData_es.json\", \"r\") as wikiData, open(\"googleDict.json\", 'r') as googleDict:\n",
    "    wikiData = json.loads(wikiData.read())\n",
    "    googleDict = json.loads(googleDict.read())\n",
    "\n",
    "    def delSomeEgs(meaning, translations):\n",
    "        ej_list = meaning[\"ejemplos\"]\n",
    "        eg_list = meaning[\"examples\"]\n",
    "        newEg_list = []\n",
    "        newEj_list = []\n",
    "        trans_terms = []\n",
    "        count = 0\n",
    "        for ejemplo in ej_list:\n",
    "            include = False\n",
    "            for trans in translations:\n",
    "                if include:\n",
    "                    break\n",
    "                if re.search(rf\"[\\s\\\"]{trans} \",ejemplo):\n",
    "                    newEg_list.append(eg_list[count])\n",
    "                    newEj_list.append(ejemplo)\n",
    "                    trans_terms.append(trans) \n",
    "            count += 1\n",
    "        meaning[\"examples\"] = newEg_list\n",
    "        meaning[\"ejemplos\"] = newEj_list\n",
    "        meaning[\"trans_terms\"] = trans_terms\n",
    "        return meaning\n",
    "\n",
    "    \n",
    "    classes = {\n",
    "    'article': 'artículo',\n",
    "    'preposition': 'preposición',\n",
    "    'adverb': 'adverbio',\n",
    "    'adjective': 'adjetivo',\n",
    "    'noun': 'sustantivo',\n",
    "    'conjunction': 'conjunción',\n",
    "    'determiner': 'adjetivo',\n",
    "    'pronoun': 'pronombre',\n",
    "    'verb': 'verbo',\n",
    "    'proper noun': 'sustantivo',\n",
    "    'numeral': 'sustantivo',\n",
    "    'symbol': 'sustantivo'\n",
    "    }\n",
    "\n",
    "    for word in wikiData:\n",
    "        word_meanings = []\n",
    "        for meaning in wikiData[word][\"meanings\"]:\n",
    "            pos = meaning[\"class\"]\n",
    "            if pos == \"interjection\":\n",
    "                continue\n",
    "            pos = classes[pos]\n",
    "            if \"dict\" in googleDict[word]:\n",
    "                for entry in googleDict[word][\"dict\"]:\n",
    "                    if entry[\"pos\"] == pos:\n",
    "                        word_meanings.append(delSomeEgs(meaning, entry[\"terms\"]))                     \n",
    "        wikiData[word][\"meanings\"] = word_meanings\n",
    "\n",
    "\n",
    "with open(\"ownDict.json\", \"w\") as f:\n",
    "    json.dump(wikiData, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dcbda5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['article', 'preposition', 'symbol', 'adverb', 'adjective', 'noun', 'conjunction', 'determiner', 'pronoun', 'verb', 'interjection', 'proper noun', 'numeral']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"wikiData.json\", \"r\") as f:\n",
    "    wikiData = json.loads(f.read())\n",
    "    classes = []\n",
    "    for word in wikiData:\n",
    "        for meaning in wikiData[word][\"meanings\"]:\n",
    "            wordClass = meaning[\"class\"]\n",
    "            if wordClass not in classes:\n",
    "                classes.append(wordClass)\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ed3abf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['artículo', 'adjetivo', 'preposición', 'adverbio', 'sustantivo', 'conjunción', 'pronombre', 'verbo', '', 'partícula']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"googleDict.json\", \"r\") as f:\n",
    "    Data = json.loads(f.read())\n",
    "    classes = []\n",
    "    for word in Data:\n",
    "        if \"dict\" in Data[word]:\n",
    "            for meaning in Data[word][\"dict\"]:\n",
    "                wordClass = meaning[\"pos\"]\n",
    "                if wordClass not in classes:\n",
    "                    classes.append(wordClass)\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cecdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46288a96d9b0371300585bfe55be2ba8c17bcbde38d0bc0b0832f4399a2cf23e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
